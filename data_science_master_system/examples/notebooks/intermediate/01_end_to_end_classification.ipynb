{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìà End-to-End Classification Pipeline\n",
                "\n",
                "A complete production-ready classification workflow from raw data to deployment.\n",
                "\n",
                "## Workflow\n",
                "1. Data loading and validation\n",
                "2. Exploratory data analysis\n",
                "3. Feature engineering\n",
                "4. Model training with hyperparameter tuning\n",
                "5. Model evaluation and interpretation\n",
                "6. Model deployment preparation\n",
                "\n",
                "**Level**: Intermediate  \n",
                "**Time Required**: ~45 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '../../')\n",
                "\n",
                "from data_science_master_system import *\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"‚úÖ All imports ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading and Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data\n",
                "loader = DataLoader()\n",
                "df = loader.read('../data/csv/customer_churn.csv')\n",
                "\n",
                "# Validate data quality\n",
                "from data_science_master_system.utils.validators import validate_dataframe\n",
                "\n",
                "validate_dataframe(df, required_columns=['customer_id', 'churn'], min_rows=100)\n",
                "print(f\"‚úÖ Data validated: {df.shape}\")\n",
                "\n",
                "# Check for issues\n",
                "print(f\"\\nüîç Data Quality:\")\n",
                "print(f\"  Missing values: {df.isnull().sum().sum()}\")\n",
                "print(f\"  Duplicates: {df.duplicated().sum()}\")\n",
                "print(f\"  Class balance: {df['churn'].value_counts().to_dict()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Engineering with Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove ID column\n",
                "df_features = df.drop(columns=['customer_id'])\n",
                "\n",
                "# Automatic feature generation\n",
                "factory = FeatureFactory()\n",
                "\n",
                "# Generate datetime-like features from tenure\n",
                "df_features['tenure_years'] = df_features['tenure_months'] / 12\n",
                "df_features['is_new_customer'] = (df_features['tenure_months'] < 6).astype(int)\n",
                "df_features['is_long_term'] = (df_features['tenure_months'] > 36).astype(int)\n",
                "\n",
                "# Create interaction features\n",
                "df_features['charges_per_month'] = df_features['total_charges'] / (df_features['tenure_months'] + 1)\n",
                "df_features['support_ratio'] = df_features['num_support_tickets'] / (df_features['tenure_months'] + 1)\n",
                "\n",
                "print(f\"Features after engineering: {df_features.shape[1]}\")\n",
                "df_features.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Prepare for Modeling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split features and target\n",
                "X = df_features.drop(columns=['churn'])\n",
                "y = df_features['churn']\n",
                "\n",
                "# Handle categorical variables\n",
                "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
                "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
                "\n",
                "# Train-test split\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Training: {X_train.shape}, Test: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Hyperparameter Tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "# Define parameter grid\n",
                "param_grid = {\n",
                "    'n_estimators': [50, 100, 200],\n",
                "    'max_depth': [5, 10, None],\n",
                "    'min_samples_split': [2, 5],\n",
                "}\n",
                "\n",
                "# Grid search\n",
                "rf = RandomForestClassifier(random_state=42)\n",
                "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
                "grid_search.fit(X_train, y_train)\n",
                "\n",
                "print(f\"Best parameters: {grid_search.best_params_}\")\n",
                "print(f\"Best CV score: {grid_search.best_score_:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train final model\n",
                "best_model = ClassificationModel('random_forest', **grid_search.best_params_)\n",
                "best_model.fit(X_train, y_train)\n",
                "\n",
                "# Evaluate\n",
                "y_pred = best_model.predict(X_test)\n",
                "y_proba = best_model.predict_proba(X_test)\n",
                "\n",
                "metrics = calculate_metrics(y_test, y_pred, 'classification', y_proba)\n",
                "\n",
                "print(\"\\nüìä Final Model Performance:\")\n",
                "for k, v in metrics.items():\n",
                "    print(f\"  {k}: {v:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Interpretation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance\n",
                "importance_df = best_model.feature_importance(top_n=15)\n",
                "\n",
                "plotter = Plotter()\n",
                "fig = plotter.feature_importance(importance_df, title='Top 15 Features')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC Curve\n",
                "fig = plotter.roc_curve(y_test, y_proba[:, 1], title='ROC Curve')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix\n",
                "from data_science_master_system.evaluation.metrics import ClassificationMetrics\n",
                "\n",
                "cm = ClassificationMetrics.confusion_matrix(y_test, y_pred)\n",
                "fig = plotter.confusion_matrix(cm, labels=['No Churn', 'Churn'], normalize=True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save and Deploy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the model\n",
                "best_model.save('churn_model_production.joblib')\n",
                "print(\"‚úÖ Model saved!\")\n",
                "\n",
                "# Example prediction function for deployment\n",
                "def predict_churn(customer_data: dict) -> dict:\n",
                "    \"\"\"Predict churn probability for a customer.\"\"\"\n",
                "    model = ClassificationModel.load('churn_model_production.joblib')\n",
                "    df = pd.DataFrame([customer_data])\n",
                "    # Apply same preprocessing...\n",
                "    df_encoded = pd.get_dummies(df)\n",
                "    # Align columns with training data\n",
                "    proba = model.predict_proba(df_encoded)[0, 1]\n",
                "    return {'churn_probability': proba, 'will_churn': proba > 0.5}\n",
                "\n",
                "print(\"\\nüì¶ Deployment function ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Summary\n",
                "\n",
                "Complete production workflow:\n",
                "1. ‚úÖ Data loading and validation\n",
                "2. ‚úÖ Feature engineering\n",
                "3. ‚úÖ Hyperparameter tuning\n",
                "4. ‚úÖ Model evaluation\n",
                "5. ‚úÖ Model interpretation\n",
                "6. ‚úÖ Deployment preparation"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}