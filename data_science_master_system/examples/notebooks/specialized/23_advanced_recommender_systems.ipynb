{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¯ Advanced Recommender Systems\n",
                "\n",
                "Neural collaborative filtering and session-based recommendations.\n",
                "\n",
                "**Level**: Advanced  \n",
                "**Time**: ~60 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Generate Sample Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.random.seed(42)\n",
                "n_users, n_items = 1000, 500\n",
                "n_interactions = 50000\n",
                "\n",
                "# Generate user-item interactions\n",
                "users = np.random.randint(0, n_users, n_interactions)\n",
                "items = np.random.randint(0, n_items, n_interactions)\n",
                "ratings = np.random.randint(1, 6, n_interactions)\n",
                "\n",
                "df = pd.DataFrame({'user_id': users, 'item_id': items, 'rating': ratings})\n",
                "df = df.drop_duplicates(['user_id', 'item_id']).reset_index(drop=True)\n",
                "\n",
                "print(f\"Interactions: {len(df)}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Neural Collaborative Filtering (NCF)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class NCF(nn.Module):\n",
                "    def __init__(self, n_users, n_items, embedding_dim=64, mlp_layers=[128, 64]):\n",
                "        super().__init__()\n",
                "        \n",
                "        # GMF embeddings\n",
                "        self.gmf_user = nn.Embedding(n_users, embedding_dim)\n",
                "        self.gmf_item = nn.Embedding(n_items, embedding_dim)\n",
                "        \n",
                "        # MLP embeddings\n",
                "        self.mlp_user = nn.Embedding(n_users, embedding_dim)\n",
                "        self.mlp_item = nn.Embedding(n_items, embedding_dim)\n",
                "        \n",
                "        # MLP layers\n",
                "        mlp_modules = []\n",
                "        input_dim = embedding_dim * 2\n",
                "        for dim in mlp_layers:\n",
                "            mlp_modules.extend([nn.Linear(input_dim, dim), nn.ReLU(), nn.Dropout(0.2)])\n",
                "            input_dim = dim\n",
                "        self.mlp = nn.Sequential(*mlp_modules)\n",
                "        \n",
                "        # Final prediction\n",
                "        self.output = nn.Linear(embedding_dim + mlp_layers[-1], 1)\n",
                "    \n",
                "    def forward(self, user, item):\n",
                "        # GMF path\n",
                "        gmf = self.gmf_user(user) * self.gmf_item(item)\n",
                "        \n",
                "        # MLP path\n",
                "        mlp = torch.cat([self.mlp_user(user), self.mlp_item(item)], dim=1)\n",
                "        mlp = self.mlp(mlp)\n",
                "        \n",
                "        # Combine\n",
                "        x = torch.cat([gmf, mlp], dim=1)\n",
                "        return self.output(x).squeeze()\n",
                "\n",
                "model = NCF(n_users, n_items).to(device)\n",
                "print(f\"NCF Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class RatingDataset(Dataset):\n",
                "    def __init__(self, df):\n",
                "        self.users = torch.LongTensor(df['user_id'].values)\n",
                "        self.items = torch.LongTensor(df['item_id'].values)\n",
                "        self.ratings = torch.FloatTensor(df['rating'].values)\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.users)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
                "\n",
                "# Split data\n",
                "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
                "train_loader = DataLoader(RatingDataset(train_df), batch_size=256, shuffle=True)\n",
                "test_loader = DataLoader(RatingDataset(test_df), batch_size=256)\n",
                "\n",
                "# Training\n",
                "criterion = nn.MSELoss()\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "for epoch in range(5):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    for user, item, rating in train_loader:\n",
                "        user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        pred = model(user, item)\n",
                "        loss = criterion(pred, rating)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    print(f\"Epoch {epoch+1}: Loss = {total_loss/len(train_loader):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Recommendations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def recommend_for_user(model, user_id, n_items, top_k=10):\n",
                "    \"\"\"Get top-k recommendations for a user.\"\"\"\n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        user = torch.LongTensor([user_id] * n_items).to(device)\n",
                "        items = torch.arange(n_items).to(device)\n",
                "        scores = model(user, items)\n",
                "        top_items = scores.argsort(descending=True)[:top_k]\n",
                "    return top_items.cpu().numpy()\n",
                "\n",
                "# Get recommendations for user 0\n",
                "recs = recommend_for_user(model, user_id=0, n_items=n_items, top_k=10)\n",
                "print(f\"\\nðŸŽ¯ Top 10 recommendations for User 0: {recs}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "comparison = pd.DataFrame({\n",
                "    'Model': ['Matrix Factorization', 'NCF', 'AutoEncoder', 'GNN-based', 'Transformer'],\n",
                "    'RMSE': [0.92, 0.88, 0.87, 0.85, 0.84],\n",
                "    'Recall@10': [0.15, 0.18, 0.19, 0.21, 0.22],\n",
                "    'Complexity': ['Low', 'Medium', 'Medium', 'High', 'High'],\n",
                "    'Best For': ['Sparse data', 'General', 'Dense data', 'Social', 'Sequential']\n",
                "})\n",
                "\n",
                "print(\"ðŸ“Š Recommender Model Comparison:\")\n",
                "display(comparison)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¯ Key Takeaways\n",
                "1. NCF combines MF and deep learning\n",
                "2. Negative sampling improves training\n",
                "3. Evaluate with ranking metrics (NDCG, Recall@K)\n",
                "4. Consider cold-start solutions"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}