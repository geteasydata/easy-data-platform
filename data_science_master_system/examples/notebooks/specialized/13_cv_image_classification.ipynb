{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üñºÔ∏è Image Classification with CNNs & Transfer Learning\n",
                "\n",
                "Complete deep learning pipeline for image classification.\n",
                "\n",
                "## Topics\n",
                "1. Building CNNs from scratch\n",
                "2. Transfer learning with EfficientNet, ResNet\n",
                "3. Data augmentation\n",
                "4. Model evaluation and deployment\n",
                "\n",
                "**Level**: Specialized  \n",
                "**Time**: ~60 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms\n",
                "from torch.utils.data import DataLoader\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading with Augmentation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define transforms\n",
                "train_transform = transforms.Compose([\n",
                "    transforms.RandomResizedCrop(224),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomRotation(15),\n",
                "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "test_transform = transforms.Compose([\n",
                "    transforms.Resize(256),\n",
                "    transforms.CenterCrop(224),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "# Use CIFAR-10 for demo\n",
                "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
                "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
                "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
                "\n",
                "classes = train_dataset.classes\n",
                "print(f\"Classes: {classes}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Custom CNN Architecture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CustomCNN(nn.Module):\n",
                "    def __init__(self, num_classes=10):\n",
                "        super().__init__()\n",
                "        self.features = nn.Sequential(\n",
                "            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
                "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
                "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
                "            nn.AdaptiveAvgPool2d(1)\n",
                "        )\n",
                "        self.classifier = nn.Sequential(\n",
                "            nn.Flatten(),\n",
                "            nn.Linear(256, 128), nn.ReLU(), nn.Dropout(0.5),\n",
                "            nn.Linear(128, num_classes)\n",
                "        )\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = self.features(x)\n",
                "        return self.classifier(x)\n",
                "\n",
                "model_custom = CustomCNN(len(classes)).to(device)\n",
                "print(f\"Parameters: {sum(p.numel() for p in model_custom.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Transfer Learning with EfficientNet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
                "\n",
                "def create_efficientnet(num_classes, freeze_backbone=True):\n",
                "    model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
                "    if freeze_backbone:\n",
                "        for param in model.parameters():\n",
                "            param.requires_grad = False\n",
                "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
                "    return model\n",
                "\n",
                "model_effnet = create_efficientnet(len(classes)).to(device)\n",
                "print(f\"EfficientNet parameters: {sum(p.numel() for p in model_effnet.parameters() if p.requires_grad):,} trainable\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_epoch(model, loader, criterion, optimizer):\n",
                "    model.train()\n",
                "    total_loss, correct, total = 0, 0, 0\n",
                "    for images, labels in loader:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "        _, predicted = outputs.max(1)\n",
                "        correct += predicted.eq(labels).sum().item()\n",
                "        total += labels.size(0)\n",
                "    return total_loss / len(loader), correct / total\n",
                "\n",
                "def evaluate(model, loader):\n",
                "    model.eval()\n",
                "    correct, total = 0, 0\n",
                "    with torch.no_grad():\n",
                "        for images, labels in loader:\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            outputs = model(images)\n",
                "            _, predicted = outputs.max(1)\n",
                "            correct += predicted.eq(labels).sum().item()\n",
                "            total += labels.size(0)\n",
                "    return correct / total\n",
                "\n",
                "# Train EfficientNet\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = torch.optim.Adam(model_effnet.classifier.parameters(), lr=0.001)\n",
                "\n",
                "print(\"Training EfficientNet (transfer learning)...\")\n",
                "for epoch in range(3):\n",
                "    loss, acc = train_epoch(model_effnet, train_loader, criterion, optimizer)\n",
                "    val_acc = evaluate(model_effnet, test_loader)\n",
                "    print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Train Acc={acc:.4f}, Val Acc={val_acc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torchvision.models import resnet18, ResNet18_Weights, vgg16, VGG16_Weights\n",
                "\n",
                "models_to_compare = {\n",
                "    'Custom CNN': CustomCNN(len(classes)),\n",
                "    'ResNet18': resnet18(weights=ResNet18_Weights.DEFAULT),\n",
                "    'EfficientNet-B0': efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT),\n",
                "}\n",
                "\n",
                "# Modify classifiers\n",
                "models_to_compare['ResNet18'].fc = nn.Linear(512, len(classes))\n",
                "models_to_compare['EfficientNet-B0'].classifier[1] = nn.Linear(1280, len(classes))\n",
                "\n",
                "comparison_results = []\n",
                "for name, model in models_to_compare.items():\n",
                "    params = sum(p.numel() for p in model.parameters())\n",
                "    comparison_results.append({'Model': name, 'Parameters': f'{params:,}'})\n",
                "\n",
                "import pandas as pd\n",
                "print(\"\\nüìä Model Comparison:\")\n",
                "display(pd.DataFrame(comparison_results))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Deployment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model\n",
                "torch.save(model_effnet.state_dict(), 'efficientnet_classifier.pth')\n",
                "\n",
                "# Export to ONNX for deployment\n",
                "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
                "torch.onnx.export(model_effnet, dummy_input, 'model.onnx', input_names=['image'], output_names=['class'])\n",
                "print(\"‚úÖ Model exported to ONNX for deployment\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Key Takeaways\n",
                "1. Transfer learning is faster than training from scratch\n",
                "2. Data augmentation improves generalization\n",
                "3. EfficientNet gives best accuracy/compute tradeoff\n",
                "4. ONNX export enables cross-platform deployment"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}