{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ¤– NLP with Transformers: BERT Classification\n",
                "\n",
                "Text classification using BERT, RoBERTa, and DistilBERT.\n",
                "\n",
                "**Level**: Specialized  \n",
                "**Time**: ~60 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
                "from datasets import load_dataset\n",
                "import numpy as np\n",
                "from sklearn.metrics import accuracy_score, f1_score\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load IMDB dataset\n",
                "dataset = load_dataset('imdb')\n",
                "print(f\"Train: {len(dataset['train'])}, Test: {len(dataset['test'])}\")\n",
                "print(f\"\\nSample: {dataset['train'][0]['text'][:200]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Tokenization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_name = 'distilbert-base-uncased'\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "\n",
                "def tokenize_function(examples):\n",
                "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=256)\n",
                "\n",
                "# Tokenize (use subset for demo)\n",
                "small_train = dataset['train'].select(range(1000))\n",
                "small_test = dataset['test'].select(range(500))\n",
                "\n",
                "tokenized_train = small_train.map(tokenize_function, batched=True)\n",
                "tokenized_test = small_test.map(tokenize_function, batched=True)\n",
                "\n",
                "print(\"âœ… Tokenization complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Pretrained Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
                "model.to(device)\n",
                "\n",
                "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training with HuggingFace Trainer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_metrics(eval_pred):\n",
                "    predictions, labels = eval_pred\n",
                "    predictions = np.argmax(predictions, axis=1)\n",
                "    return {'accuracy': accuracy_score(labels, predictions), 'f1': f1_score(labels, predictions)}\n",
                "\n",
                "training_args = TrainingArguments(\n",
                "    output_dir='./results',\n",
                "    num_train_epochs=2,\n",
                "    per_device_train_batch_size=16,\n",
                "    per_device_eval_batch_size=32,\n",
                "    warmup_steps=100,\n",
                "    weight_decay=0.01,\n",
                "    logging_steps=50,\n",
                "    evaluation_strategy='epoch',\n",
                ")\n",
                "\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_train,\n",
                "    eval_dataset=tokenized_test,\n",
                "    compute_metrics=compute_metrics,\n",
                ")\n",
                "\n",
                "# Train\n",
                "trainer.train()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "models_comparison = pd.DataFrame({\n",
                "    'Model': ['BERT-base', 'RoBERTa-base', 'DistilBERT', 'ALBERT-base', 'DeBERTa-base'],\n",
                "    'Parameters': ['110M', '125M', '66M', '12M', '140M'],\n",
                "    'Speed': ['1x', '1x', '2x', '1.7x', '0.8x'],\n",
                "    'GLUE Score': [79.6, 83.2, 77.0, 80.1, 86.8],\n",
                "    'Best For': ['General', 'Accuracy', 'Speed', 'Memory', 'Quality']\n",
                "})\n",
                "\n",
                "print(\"ðŸ“Š Transformer Models Comparison:\")\n",
                "display(models_comparison)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_sentiment(text):\n",
                "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=256).to(device)\n",
                "    with torch.no_grad():\n",
                "        outputs = model(**inputs)\n",
                "    probs = torch.softmax(outputs.logits, dim=1)\n",
                "    pred = torch.argmax(probs, dim=1).item()\n",
                "    return 'Positive' if pred == 1 else 'Negative', probs[0][pred].item()\n",
                "\n",
                "# Test\n",
                "test_texts = [\n",
                "    \"This movie was absolutely fantastic! Best film I've seen this year.\",\n",
                "    \"Terrible waste of time. The acting was horrible.\"\n",
                "]\n",
                "\n",
                "print(\"\\nðŸ”® Predictions:\")\n",
                "for text in test_texts:\n",
                "    sentiment, conf = predict_sentiment(text)\n",
                "    print(f\"  {sentiment} ({conf:.1%}): {text[:50]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¯ Key Takeaways\n",
                "1. DistilBERT is 2x faster with 97% performance\n",
                "2. Fine-tuning beats training from scratch\n",
                "3. HuggingFace Trainer simplifies training\n",
                "4. Use gradient checkpointing for large models"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}