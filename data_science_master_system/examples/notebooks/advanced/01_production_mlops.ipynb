{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš€ Production ML Pipeline with MLOps\n",
                "\n",
                "Advanced end-to-end pipeline with production best practices.\n",
                "\n",
                "## Topics\n",
                "1. Data versioning and validation\n",
                "2. Feature store patterns\n",
                "3. Model registry\n",
                "4. A/B testing framework\n",
                "5. Monitoring and alerting\n",
                "\n",
                "**Level**: Advanced  \n",
                "**Time Required**: ~60 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '../../')\n",
                "\n",
                "from data_science_master_system import *\n",
                "from datetime import datetime\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import json\n",
                "import hashlib\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"âœ… Ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Versioning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DataVersioner:\n",
                "    \"\"\"Simple data versioning system.\"\"\"\n",
                "    \n",
                "    def __init__(self, storage_path: str = './data_versions'):\n",
                "        self.storage_path = Path(storage_path)\n",
                "        self.storage_path.mkdir(exist_ok=True)\n",
                "        self.registry_path = self.storage_path / 'registry.json'\n",
                "        self.registry = self._load_registry()\n",
                "    \n",
                "    def _load_registry(self):\n",
                "        if self.registry_path.exists():\n",
                "            return json.load(open(self.registry_path))\n",
                "        return {}\n",
                "    \n",
                "    def _save_registry(self):\n",
                "        json.dump(self.registry, open(self.registry_path, 'w'), indent=2)\n",
                "    \n",
                "    def _compute_hash(self, df):\n",
                "        return hashlib.md5(pd.util.hash_pandas_object(df).values).hexdigest()[:8]\n",
                "    \n",
                "    def save_version(self, df, name: str, description: str = ''):\n",
                "        \"\"\"Save a version of the dataset.\"\"\"\n",
                "        version_id = f\"{name}_v{len(self.registry.get(name, []))+1}\"\n",
                "        data_hash = self._compute_hash(df)\n",
                "        \n",
                "        # Save data\n",
                "        file_path = self.storage_path / f\"{version_id}.parquet\"\n",
                "        df.to_parquet(file_path)\n",
                "        \n",
                "        # Update registry\n",
                "        if name not in self.registry:\n",
                "            self.registry[name] = []\n",
                "        \n",
                "        self.registry[name].append({\n",
                "            'version_id': version_id,\n",
                "            'timestamp': datetime.now().isoformat(),\n",
                "            'hash': data_hash,\n",
                "            'shape': list(df.shape),\n",
                "            'description': description,\n",
                "            'file_path': str(file_path)\n",
                "        })\n",
                "        \n",
                "        self._save_registry()\n",
                "        print(f\"âœ… Saved {version_id}\")\n",
                "        return version_id\n",
                "    \n",
                "    def load_version(self, version_id: str):\n",
                "        \"\"\"Load a specific version.\"\"\"\n",
                "        for versions in self.registry.values():\n",
                "            for v in versions:\n",
                "                if v['version_id'] == version_id:\n",
                "                    return pd.read_parquet(v['file_path'])\n",
                "        raise ValueError(f\"Version {version_id} not found\")\n",
                "    \n",
                "    def list_versions(self, name: str):\n",
                "        \"\"\"List all versions of a dataset.\"\"\"\n",
                "        return self.registry.get(name, [])\n",
                "\n",
                "# Example usage\n",
                "versioner = DataVersioner('./data_versions')\n",
                "\n",
                "loader = DataLoader()\n",
                "df = loader.read('../data/csv/customer_churn.csv')\n",
                "\n",
                "versioner.save_version(df, 'customer_churn', 'Initial raw data')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Store Pattern"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class FeatureStore:\n",
                "    \"\"\"Simple feature store for ML features.\"\"\"\n",
                "    \n",
                "    def __init__(self, storage_path: str = './feature_store'):\n",
                "        self.storage_path = Path(storage_path)\n",
                "        self.storage_path.mkdir(exist_ok=True)\n",
                "        self.catalog = {}\n",
                "    \n",
                "    def register_feature_group(self, name: str, df: pd.DataFrame, \n",
                "                               entity_key: str, features: list, description: str = ''):\n",
                "        \"\"\"Register a feature group.\"\"\"\n",
                "        # Save features\n",
                "        file_path = self.storage_path / f\"{name}.parquet\"\n",
                "        df[[entity_key] + features].to_parquet(file_path)\n",
                "        \n",
                "        self.catalog[name] = {\n",
                "            'entity_key': entity_key,\n",
                "            'features': features,\n",
                "            'description': description,\n",
                "            'created_at': datetime.now().isoformat(),\n",
                "            'file_path': str(file_path)\n",
                "        }\n",
                "        print(f\"âœ… Registered feature group: {name}\")\n",
                "    \n",
                "    def get_features(self, name: str, entity_ids: list = None):\n",
                "        \"\"\"Retrieve features from the store.\"\"\"\n",
                "        if name not in self.catalog:\n",
                "            raise ValueError(f\"Feature group {name} not found\")\n",
                "        \n",
                "        df = pd.read_parquet(self.catalog[name]['file_path'])\n",
                "        \n",
                "        if entity_ids is not None:\n",
                "            entity_key = self.catalog[name]['entity_key']\n",
                "            df = df[df[entity_key].isin(entity_ids)]\n",
                "        \n",
                "        return df\n",
                "    \n",
                "    def list_feature_groups(self):\n",
                "        return pd.DataFrame([\n",
                "            {'name': k, **{kk: vv for kk, vv in v.items() if kk != 'file_path'}}\n",
                "            for k, v in self.catalog.items()\n",
                "        ])\n",
                "\n",
                "# Example usage\n",
                "store = FeatureStore('./feature_store')\n",
                "\n",
                "# Create some features\n",
                "df['tenure_years'] = df['tenure_months'] / 12\n",
                "df['charges_ratio'] = df['total_charges'] / (df['monthly_charges'] + 1)\n",
                "\n",
                "store.register_feature_group(\n",
                "    name='customer_features',\n",
                "    df=df,\n",
                "    entity_key='customer_id',\n",
                "    features=['tenure_years', 'charges_ratio', 'num_support_tickets'],\n",
                "    description='Customer engagement features'\n",
                ")\n",
                "\n",
                "# Retrieve features\n",
                "features = store.get_features('customer_features', entity_ids=['CUST_00001', 'CUST_00002'])\n",
                "print(\"\\nRetrieved features:\")\n",
                "display(features)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Registry"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import joblib\n",
                "\n",
                "class ModelRegistry:\n",
                "    \"\"\"Model registry for ML model lifecycle management.\"\"\"\n",
                "    \n",
                "    STAGES = ['development', 'staging', 'production', 'archived']\n",
                "    \n",
                "    def __init__(self, storage_path: str = './model_registry'):\n",
                "        self.storage_path = Path(storage_path)\n",
                "        self.storage_path.mkdir(exist_ok=True)\n",
                "        self.registry_path = self.storage_path / 'registry.json'\n",
                "        self.registry = self._load_registry()\n",
                "    \n",
                "    def _load_registry(self):\n",
                "        if self.registry_path.exists():\n",
                "            return json.load(open(self.registry_path))\n",
                "        return {}\n",
                "    \n",
                "    def _save_registry(self):\n",
                "        json.dump(self.registry, open(self.registry_path, 'w'), indent=2, default=str)\n",
                "    \n",
                "    def register_model(self, name: str, model, metrics: dict, \n",
                "                       params: dict = None, description: str = ''):\n",
                "        \"\"\"Register a new model version.\"\"\"\n",
                "        if name not in self.registry:\n",
                "            self.registry[name] = []\n",
                "        \n",
                "        version = len(self.registry[name]) + 1\n",
                "        model_id = f\"{name}_v{version}\"\n",
                "        \n",
                "        # Save model\n",
                "        model_path = self.storage_path / f\"{model_id}.joblib\"\n",
                "        joblib.dump(model, model_path)\n",
                "        \n",
                "        self.registry[name].append({\n",
                "            'model_id': model_id,\n",
                "            'version': version,\n",
                "            'stage': 'development',\n",
                "            'metrics': metrics,\n",
                "            'params': params or {},\n",
                "            'description': description,\n",
                "            'created_at': datetime.now().isoformat(),\n",
                "            'model_path': str(model_path)\n",
                "        })\n",
                "        \n",
                "        self._save_registry()\n",
                "        print(f\"âœ… Registered {model_id}\")\n",
                "        return model_id\n",
                "    \n",
                "    def transition_stage(self, model_id: str, stage: str):\n",
                "        \"\"\"Transition model to a new stage.\"\"\"\n",
                "        if stage not in self.STAGES:\n",
                "            raise ValueError(f\"Invalid stage: {stage}\")\n",
                "        \n",
                "        for models in self.registry.values():\n",
                "            for m in models:\n",
                "                if m['model_id'] == model_id:\n",
                "                    m['stage'] = stage\n",
                "                    self._save_registry()\n",
                "                    print(f\"âœ… {model_id} â†’ {stage}\")\n",
                "                    return\n",
                "    \n",
                "    def get_production_model(self, name: str):\n",
                "        \"\"\"Get the production model.\"\"\"\n",
                "        for m in reversed(self.registry.get(name, [])):\n",
                "            if m['stage'] == 'production':\n",
                "                return joblib.load(m['model_path'])\n",
                "        raise ValueError(f\"No production model for {name}\")\n",
                "    \n",
                "    def list_models(self, name: str = None):\n",
                "        \"\"\"List all registered models.\"\"\"\n",
                "        models = []\n",
                "        for n, versions in self.registry.items():\n",
                "            if name is None or n == name:\n",
                "                for m in versions:\n",
                "                    models.append({'name': n, **m})\n",
                "        return pd.DataFrame(models)\n",
                "\n",
                "# Example usage\n",
                "registry = ModelRegistry('./model_registry')\n",
                "\n",
                "# Train and register a model\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X = df.drop(columns=['customer_id', 'churn']).select_dtypes(include=[np.number])\n",
                "y = df['churn']\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "from sklearn.metrics import accuracy_score, f1_score\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "registry.register_model(\n",
                "    name='churn_classifier',\n",
                "    model=model,\n",
                "    metrics={'accuracy': accuracy_score(y_test, y_pred), 'f1': f1_score(y_test, y_pred)},\n",
                "    params={'n_estimators': 100},\n",
                "    description='Initial RF model'\n",
                ")\n",
                "\n",
                "# Promote to production\n",
                "registry.transition_stage('churn_classifier_v1', 'production')\n",
                "\n",
                "print(\"\\nRegistered models:\")\n",
                "display(registry.list_models())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. A/B Testing Framework"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ABTest:\n",
                "    \"\"\"A/B testing framework for ML models.\"\"\"\n",
                "    \n",
                "    def __init__(self, model_a, model_b, split_ratio: float = 0.5):\n",
                "        self.model_a = model_a\n",
                "        self.model_b = model_b\n",
                "        self.split_ratio = split_ratio\n",
                "        self.results = {'A': [], 'B': []}\n",
                "    \n",
                "    def predict(self, X, record_id: str):\n",
                "        \"\"\"Make prediction using A/B split.\"\"\"\n",
                "        # Deterministic split based on record_id\n",
                "        hash_val = int(hashlib.md5(str(record_id).encode()).hexdigest(), 16)\n",
                "        use_b = (hash_val % 100) < (self.split_ratio * 100)\n",
                "        \n",
                "        if use_b:\n",
                "            pred = self.model_b.predict(X)[0]\n",
                "            self.results['B'].append({'id': record_id, 'prediction': pred})\n",
                "            return pred, 'B'\n",
                "        else:\n",
                "            pred = self.model_a.predict(X)[0]\n",
                "            self.results['A'].append({'id': record_id, 'prediction': pred})\n",
                "            return pred, 'A'\n",
                "    \n",
                "    def record_outcome(self, record_id: str, actual: int):\n",
                "        \"\"\"Record the actual outcome.\"\"\"\n",
                "        for variant in ['A', 'B']:\n",
                "            for r in self.results[variant]:\n",
                "                if r['id'] == record_id:\n",
                "                    r['actual'] = actual\n",
                "                    return\n",
                "    \n",
                "    def evaluate(self):\n",
                "        \"\"\"Evaluate A/B test results.\"\"\"\n",
                "        results = {}\n",
                "        for variant in ['A', 'B']:\n",
                "            outcomes = [r for r in self.results[variant] if 'actual' in r]\n",
                "            if outcomes:\n",
                "                correct = sum(1 for r in outcomes if r['prediction'] == r['actual'])\n",
                "                results[variant] = {\n",
                "                    'count': len(outcomes),\n",
                "                    'accuracy': correct / len(outcomes)\n",
                "                }\n",
                "        return results\n",
                "\n",
                "# Example usage\n",
                "model_a = RandomForestClassifier(n_estimators=50, random_state=42)\n",
                "model_b = RandomForestClassifier(n_estimators=200, random_state=42)\n",
                "\n",
                "model_a.fit(X_train, y_train)\n",
                "model_b.fit(X_train, y_train)\n",
                "\n",
                "ab_test = ABTest(model_a, model_b, split_ratio=0.5)\n",
                "\n",
                "# Simulate predictions\n",
                "for i in range(len(X_test)):\n",
                "    record_id = f\"test_{i}\"\n",
                "    pred, variant = ab_test.predict(X_test.iloc[[i]], record_id)\n",
                "    ab_test.record_outcome(record_id, y_test.iloc[i])\n",
                "\n",
                "results = ab_test.evaluate()\n",
                "print(\"\\nðŸ“Š A/B Test Results:\")\n",
                "for variant, metrics in results.items():\n",
                "    print(f\"  Model {variant}: {metrics['count']} samples, {metrics['accuracy']:.1%} accuracy\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Monitoring & Alerting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ModelMonitor:\n",
                "    \"\"\"Monitor model performance in production.\"\"\"\n",
                "    \n",
                "    def __init__(self, baseline_metrics: dict, alert_threshold: float = 0.1):\n",
                "        self.baseline = baseline_metrics\n",
                "        self.alert_threshold = alert_threshold\n",
                "        self.history = []\n",
                "    \n",
                "    def log_prediction(self, prediction, actual=None, features=None):\n",
                "        \"\"\"Log a prediction for monitoring.\"\"\"\n",
                "        self.history.append({\n",
                "            'timestamp': datetime.now(),\n",
                "            'prediction': prediction,\n",
                "            'actual': actual,\n",
                "            'features': features\n",
                "        })\n",
                "    \n",
                "    def check_drift(self, window_size: int = 100):\n",
                "        \"\"\"Check for model drift.\"\"\"\n",
                "        if len(self.history) < window_size:\n",
                "            return {'status': 'insufficient_data'}\n",
                "        \n",
                "        recent = self.history[-window_size:]\n",
                "        outcomes = [r for r in recent if r['actual'] is not None]\n",
                "        \n",
                "        if not outcomes:\n",
                "            return {'status': 'no_outcomes'}\n",
                "        \n",
                "        correct = sum(1 for r in outcomes if r['prediction'] == r['actual'])\n",
                "        current_accuracy = correct / len(outcomes)\n",
                "        \n",
                "        drift = self.baseline.get('accuracy', 1.0) - current_accuracy\n",
                "        \n",
                "        return {\n",
                "            'status': 'alert' if drift > self.alert_threshold else 'ok',\n",
                "            'current_accuracy': current_accuracy,\n",
                "            'baseline_accuracy': self.baseline.get('accuracy'),\n",
                "            'drift': drift,\n",
                "            'samples': len(outcomes)\n",
                "        }\n",
                "    \n",
                "    def get_metrics_summary(self):\n",
                "        \"\"\"Get summary of recent metrics.\"\"\"\n",
                "        outcomes = [r for r in self.history if r['actual'] is not None]\n",
                "        if not outcomes:\n",
                "            return {}\n",
                "        \n",
                "        correct = sum(1 for r in outcomes if r['prediction'] == r['actual'])\n",
                "        return {\n",
                "            'total_predictions': len(self.history),\n",
                "            'total_outcomes': len(outcomes),\n",
                "            'accuracy': correct / len(outcomes)\n",
                "        }\n",
                "\n",
                "# Example usage\n",
                "monitor = ModelMonitor(\n",
                "    baseline_metrics={'accuracy': 0.85},\n",
                "    alert_threshold=0.1\n",
                ")\n",
                "\n",
                "# Simulate production predictions\n",
                "for i in range(len(X_test)):\n",
                "    pred = model.predict(X_test.iloc[[i]])[0]\n",
                "    monitor.log_prediction(prediction=pred, actual=y_test.iloc[i])\n",
                "\n",
                "# Check for drift\n",
                "drift_status = monitor.check_drift(window_size=50)\n",
                "print(\"\\nðŸ“Š Drift Check:\")\n",
                "for k, v in drift_status.items():\n",
                "    print(f\"  {k}: {v}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¯ Key MLOps Practices\n",
                "\n",
                "1. **Data Versioning** - Track data changes\n",
                "2. **Feature Stores** - Reusable feature pipelines\n",
                "3. **Model Registry** - Lifecycle management\n",
                "4. **A/B Testing** - Safe rollouts\n",
                "5. **Monitoring** - Catch drift early"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}