{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¬ Recommender Systems\n",
                "\n",
                "**Author**: Data Science Master System  \n",
                "**Difficulty**: â­â­â­ Advanced  \n",
                "**Time**: 60 minutes  \n",
                "**Prerequisites**: 10_model_evaluation\n",
                "\n",
                "## Learning Objectives\n",
                "- Collaborative vs Content-based filtering\n",
                "- Matrix factorization (SVD)\n",
                "- Deep learning recommendations\n",
                "- Evaluation metrics (NDCG, MAP)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Sample Ratings Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# User-Item ratings matrix\n",
                "n_users, n_items = 100, 50\n",
                "ratings = np.random.choice([0, 1, 2, 3, 4, 5], size=(n_users, n_items), p=[0.6, 0.1, 0.1, 0.1, 0.05, 0.05])\n",
                "ratings_df = pd.DataFrame(ratings, columns=[f'item_{i}' for i in range(n_items)])\n",
                "\n",
                "print(f\"Ratings matrix: {ratings.shape}\")\n",
                "print(f\"Sparsity: {(ratings == 0).sum() / ratings.size:.1%}\")\n",
                "ratings_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Collaborative Filtering (Matrix Factorization)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.decomposition import TruncatedSVD\n",
                "\n",
                "# SVD for matrix factorization\n",
                "n_factors = 10\n",
                "svd = TruncatedSVD(n_components=n_factors)\n",
                "user_factors = svd.fit_transform(ratings)\n",
                "item_factors = svd.components_.T\n",
                "\n",
                "# Reconstruct ratings\n",
                "predicted_ratings = user_factors @ item_factors.T\n",
                "\n",
                "print(f\"User factors: {user_factors.shape}\")\n",
                "print(f\"Item factors: {item_factors.shape}\")\n",
                "print(f\"Explained variance: {svd.explained_variance_ratio_.sum():.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Content-Based Filtering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Item features\n",
                "item_features = pd.DataFrame({\n",
                "    'item_id': range(10),\n",
                "    'genre': ['Action', 'Comedy', 'Action', 'Drama', 'Comedy', 'Action', 'Drama', 'Comedy', 'Action', 'Drama'],\n",
                "    'year': [2020, 2019, 2021, 2020, 2018, 2022, 2021, 2020, 2019, 2022]\n",
                "})\n",
                "\n",
                "# One-hot encode\n",
                "features = pd.get_dummies(item_features['genre'])\n",
                "\n",
                "# Cosine similarity\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "similarity = cosine_similarity(features)\n",
                "\n",
                "print(\"Content-based similarity matrix:\")\n",
                "print(pd.DataFrame(similarity[:5, :5]).round(2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Hybrid Approach"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "approaches = pd.DataFrame({\n",
                "    'Method': ['Collaborative', 'Content-Based', 'Hybrid', 'Deep Learning'],\n",
                "    'Pros': ['Serendipity', 'No cold start for items', 'Best of both', 'Complex patterns'],\n",
                "    'Cons': ['Cold start', 'Limited discovery', 'Complex', 'Data hungry'],\n",
                "    'Example': ['MovieLens', 'Spotify playlists', 'Netflix', 'YouTube']\n",
                "})\n",
                "\n",
                "display(approaches)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¯ Key Takeaways\n",
                "1. Start with matrix factorization\n",
                "2. Combine CF + content for cold start\n",
                "3. Use implicit feedback (clicks > ratings)\n",
                "4. Optimize for NDCG, not just accuracy\n",
                "\n",
                "**Next**: 24_graph_neural_networks.ipynb"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}