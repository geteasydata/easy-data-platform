{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîí Federated Learning: Privacy-Preserving ML\n",
                "\n",
                "**Author**: Data Science Master System  \n",
                "**Difficulty**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Expert  \n",
                "**Time**: 90 minutes  \n",
                "**Prerequisites**: Deep Learning, Distributed Systems\n",
                "\n",
                "## Learning Objectives\n",
                "- Understand federated learning fundamentals\n",
                "- Implement FedAvg algorithm\n",
                "- Apply differential privacy\n",
                "- Use Flower framework for production FL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from typing import List, Dict, Tuple\n",
                "import copy\n",
                "\n",
                "np.random.seed(42)\n",
                "torch.manual_seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Federated Learning Concepts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "concepts = '''\n",
                "üîí FEDERATED LEARNING\n",
                "\n",
                "Traditional ML:     Data ‚Üí Central Server ‚Üí Train ‚Üí Model\n",
                "Federated ML:       Model ‚Üí Devices ‚Üí Local Train ‚Üí Aggregate\n",
                "\n",
                "KEY PRINCIPLES:\n",
                "1. Data never leaves the device\n",
                "2. Only model updates are shared\n",
                "3. Central server aggregates updates\n",
                "4. Privacy is preserved by design\n",
                "\n",
                "USE CASES:\n",
                "- Healthcare: Train on patient data across hospitals (HIPAA compliant)\n",
                "- Finance: Fraud detection without sharing transaction data\n",
                "- Mobile: Keyboard prediction without uploading messages\n",
                "- IoT: Edge devices with sensitive sensor data\n",
                "'''\n",
                "print(concepts)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Simple Model for FL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleNN(nn.Module):\n",
                "    \"\"\"Simple neural network for demonstration.\"\"\"\n",
                "    def __init__(self, input_dim=10, hidden_dim=32, output_dim=2):\n",
                "        super().__init__()\n",
                "        self.net = nn.Sequential(\n",
                "            nn.Linear(input_dim, hidden_dim),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(hidden_dim, output_dim)\n",
                "        )\n",
                "    \n",
                "    def forward(self, x):\n",
                "        return self.net(x)\n",
                "\n",
                "model = SimpleNN()\n",
                "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. FedAvg Algorithm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class FederatedAveraging:\n",
                "    \"\"\"Federated Averaging (FedAvg) implementation.\"\"\"\n",
                "    \n",
                "    def __init__(self, global_model: nn.Module, num_clients: int):\n",
                "        self.global_model = global_model\n",
                "        self.num_clients = num_clients\n",
                "    \n",
                "    def client_update(self, model: nn.Module, data: torch.Tensor, \n",
                "                      labels: torch.Tensor, epochs: int = 5, lr: float = 0.01):\n",
                "        \"\"\"Train model on client's local data.\"\"\"\n",
                "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
                "        criterion = nn.CrossEntropyLoss()\n",
                "        \n",
                "        model.train()\n",
                "        for _ in range(epochs):\n",
                "            optimizer.zero_grad()\n",
                "            outputs = model(data)\n",
                "            loss = criterion(outputs, labels)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "        \n",
                "        return model.state_dict()\n",
                "    \n",
                "    def aggregate(self, client_weights: List[Dict], sample_counts: List[int]):\n",
                "        \"\"\"Weighted average of client model weights.\"\"\"\n",
                "        total_samples = sum(sample_counts)\n",
                "        \n",
                "        # Initialize aggregated weights\n",
                "        aggregated = copy.deepcopy(client_weights[0])\n",
                "        for key in aggregated:\n",
                "            aggregated[key] = aggregated[key] * 0  # Zero out\n",
                "        \n",
                "        # Weighted sum\n",
                "        for weights, count in zip(client_weights, sample_counts):\n",
                "            weight = count / total_samples\n",
                "            for key in aggregated:\n",
                "                aggregated[key] += weights[key] * weight\n",
                "        \n",
                "        return aggregated\n",
                "    \n",
                "    def train_round(self, client_data: List[Tuple]):\n",
                "        \"\"\"Execute one round of federated training.\"\"\"\n",
                "        client_weights = []\n",
                "        sample_counts = []\n",
                "        \n",
                "        for data, labels in client_data:\n",
                "            # Each client gets a copy of global model\n",
                "            client_model = copy.deepcopy(self.global_model)\n",
                "            \n",
                "            # Local training\n",
                "            weights = self.client_update(client_model, data, labels)\n",
                "            client_weights.append(weights)\n",
                "            sample_counts.append(len(data))\n",
                "        \n",
                "        # Aggregate\n",
                "        new_weights = self.aggregate(client_weights, sample_counts)\n",
                "        self.global_model.load_state_dict(new_weights)\n",
                "        \n",
                "        return self.global_model\n",
                "\n",
                "# Demonstration\n",
                "fedavg = FederatedAveraging(SimpleNN(), num_clients=5)\n",
                "print(\"‚úÖ FedAvg initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Differential Privacy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DifferentialPrivacy:\n",
                "    \"\"\"Add differential privacy to gradients.\"\"\"\n",
                "    \n",
                "    def __init__(self, epsilon: float = 1.0, delta: float = 1e-5, max_grad_norm: float = 1.0):\n",
                "        self.epsilon = epsilon\n",
                "        self.delta = delta\n",
                "        self.max_grad_norm = max_grad_norm\n",
                "    \n",
                "    def clip_gradients(self, model: nn.Module):\n",
                "        \"\"\"Clip gradients to max_grad_norm.\"\"\"\n",
                "        total_norm = 0\n",
                "        for p in model.parameters():\n",
                "            if p.grad is not None:\n",
                "                total_norm += p.grad.data.norm(2).item() ** 2\n",
                "        total_norm = total_norm ** 0.5\n",
                "        \n",
                "        clip_coef = self.max_grad_norm / (total_norm + 1e-6)\n",
                "        if clip_coef < 1:\n",
                "            for p in model.parameters():\n",
                "                if p.grad is not None:\n",
                "                    p.grad.data.mul_(clip_coef)\n",
                "    \n",
                "    def add_noise(self, model: nn.Module, noise_scale: float):\n",
                "        \"\"\"Add Gaussian noise to gradients.\"\"\"\n",
                "        for p in model.parameters():\n",
                "            if p.grad is not None:\n",
                "                noise = torch.randn_like(p.grad) * noise_scale\n",
                "                p.grad.data.add_(noise)\n",
                "\n",
                "dp = DifferentialPrivacy(epsilon=1.0)\n",
                "print(f\"DP configured: Œµ={dp.epsilon}, Œ¥={dp.delta}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Flower Framework"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "flower_example = '''\n",
                "# Flower: Production Federated Learning Framework\n",
                "\n",
                "# Server (server.py)\n",
                "import flwr as fl\n",
                "\n",
                "strategy = fl.server.strategy.FedAvg(\n",
                "    min_fit_clients=2,\n",
                "    min_evaluate_clients=2,\n",
                "    min_available_clients=2,\n",
                ")\n",
                "\n",
                "fl.server.start_server(\n",
                "    server_address=\"0.0.0.0:8080\",\n",
                "    config=fl.server.ServerConfig(num_rounds=3),\n",
                "    strategy=strategy,\n",
                ")\n",
                "\n",
                "# Client (client.py)\n",
                "import flwr as fl\n",
                "\n",
                "class MyClient(fl.client.NumPyClient):\n",
                "    def get_parameters(self, config):\n",
                "        return [p.numpy() for p in model.parameters()]\n",
                "    \n",
                "    def fit(self, parameters, config):\n",
                "        # Train locally\n",
                "        train_model(model, trainloader)\n",
                "        return self.get_parameters({}), len(trainloader), {}\n",
                "    \n",
                "    def evaluate(self, parameters, config):\n",
                "        loss, accuracy = test_model(model, testloader)\n",
                "        return float(loss), len(testloader), {\"accuracy\": accuracy}\n",
                "\n",
                "fl.client.start_numpy_client(server_address=\"127.0.0.1:8080\", client=MyClient())\n",
                "'''\n",
                "print(flower_example)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Comparison & Trade-offs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "comparison = pd.DataFrame({\n",
                "    'Aspect': ['Privacy', 'Data Transfer', 'Accuracy', 'Communication', 'Complexity'],\n",
                "    'Centralized': ['Low', 'High (all data)', 'Best', 'Low', 'Low'],\n",
                "    'Federated': ['High', 'Low (only weights)', '~5% lower', 'High (rounds)', 'Medium'],\n",
                "    'FL + DP': ['Very High', 'Low + noise', '~10% lower', 'High', 'High']\n",
                "})\n",
                "\n",
                "print(\"üìä ML Paradigm Comparison:\")\n",
                "display(comparison)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Key Takeaways\n",
                "1. FL keeps data local - privacy by design\n",
                "2. FedAvg: simple but effective aggregation\n",
                "3. Differential privacy adds noise for extra protection\n",
                "4. Use Flower for production deployments\n",
                "5. Trade-off: privacy vs accuracy (~5-10% loss)\n",
                "\n",
                "**Next**: 27_quantum_ml.ipynb"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}