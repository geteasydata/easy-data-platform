{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ” Anomaly Detection\n",
                "\n",
                "**Author**: Data Science Master System  \n",
                "**Difficulty**: â­â­â­ Advanced  \n",
                "**Time**: 45 minutes  \n",
                "**Prerequisites**: 21_time_series_forecasting\n",
                "\n",
                "## Learning Objectives\n",
                "- Statistical methods (Z-score, IQR)\n",
                "- Isolation Forest\n",
                "- Autoencoders for anomalies\n",
                "- Streaming anomaly detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.ensemble import IsolationForest\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Generate Data with Anomalies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Normal data\n",
                "n_samples = 300\n",
                "X_normal = np.random.randn(n_samples, 2)\n",
                "\n",
                "# Inject anomalies\n",
                "n_anomalies = 20\n",
                "X_anomalies = np.random.uniform(low=-4, high=4, size=(n_anomalies, 2))\n",
                "\n",
                "X = np.vstack([X_normal, X_anomalies])\n",
                "y_true = np.array([0]*n_samples + [1]*n_anomalies)  # 0=normal, 1=anomaly\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.scatter(X[:n_samples, 0], X[:n_samples, 1], label='Normal', alpha=0.6)\n",
                "plt.scatter(X[n_samples:, 0], X[n_samples:, 1], label='Anomaly', color='red', s=100)\n",
                "plt.legend()\n",
                "plt.title('Data with Anomalies')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Isolation Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
                "y_pred = iso_forest.fit_predict(X)\n",
                "\n",
                "# Convert to binary (1=normal, -1=anomaly â†’ 0=normal, 1=anomaly)\n",
                "y_pred_binary = (y_pred == -1).astype(int)\n",
                "\n",
                "# Accuracy\n",
                "accuracy = (y_pred_binary == y_true).mean()\n",
                "print(f\"Isolation Forest Accuracy: {accuracy:.2%}\")\n",
                "\n",
                "# Visualize\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.scatter(X[y_pred == 1, 0], X[y_pred == 1, 1], label='Normal (pred)', alpha=0.6)\n",
                "plt.scatter(X[y_pred == -1, 0], X[y_pred == -1, 1], label='Anomaly (pred)', color='red', s=100)\n",
                "plt.legend()\n",
                "plt.title('Isolation Forest Predictions')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Statistical Methods"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def z_score_anomalies(data, threshold=3):\n",
                "    \"\"\"Detect anomalies using Z-score.\"\"\"\n",
                "    scaler = StandardScaler()\n",
                "    z_scores = np.abs(scaler.fit_transform(data))\n",
                "    return (z_scores > threshold).any(axis=1)\n",
                "\n",
                "def iqr_anomalies(data, k=1.5):\n",
                "    \"\"\"Detect anomalies using IQR.\"\"\"\n",
                "    anomalies = np.zeros(len(data), dtype=bool)\n",
                "    for col in range(data.shape[1]):\n",
                "        Q1, Q3 = np.percentile(data[:, col], [25, 75])\n",
                "        IQR = Q3 - Q1\n",
                "        anomalies |= (data[:, col] < Q1 - k*IQR) | (data[:, col] > Q3 + k*IQR)\n",
                "    return anomalies\n",
                "\n",
                "print(f\"Z-score anomalies: {z_score_anomalies(X).sum()}\")\n",
                "print(f\"IQR anomalies: {iqr_anomalies(X).sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Method Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "comparison = pd.DataFrame({\n",
                "    'Method': ['Z-Score', 'IQR', 'Isolation Forest', 'LOF', 'Autoencoder'],\n",
                "    'Type': ['Statistical', 'Statistical', 'ML', 'ML', 'Deep Learning'],\n",
                "    'Best For': ['Univariate', 'Robust/outliers', 'High-dim', 'Local anomalies', 'Complex patterns'],\n",
                "    'Streaming': ['Yes', 'Yes', 'No', 'No', 'Partial']\n",
                "})\n",
                "\n",
                "display(comparison)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¯ Key Takeaways\n",
                "1. Isolation Forest: Best general-purpose\n",
                "2. Z-score: Fast, simple, univariate\n",
                "3. Set contamination based on domain knowledge\n",
                "4. Combine methods for robust detection\n",
                "\n",
                "**Next**: 23_recommender_systems.ipynb"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}