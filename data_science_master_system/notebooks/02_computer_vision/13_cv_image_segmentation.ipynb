{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üñºÔ∏è Image Segmentation: U-Net & Mask R-CNN\n",
                "\n",
                "**Author**: Data Science Master System  \n",
                "**Difficulty**: ‚≠ê‚≠ê‚≠ê‚≠ê Advanced  \n",
                "**Time**: 90 minutes  \n",
                "**Prerequisites**: 12_cv_object_detection\n",
                "\n",
                "## Learning Objectives\n",
                "- Semantic vs Instance segmentation\n",
                "- Implement U-Net architecture\n",
                "- Use Mask R-CNN for instance segmentation\n",
                "- Medical imaging applications"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Segmentation Types"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "types = {\n",
                "    'Semantic': 'Classify each pixel (no instance separation)',\n",
                "    'Instance': 'Separate individual objects of same class',\n",
                "    'Panoptic': 'Semantic + Instance combined'\n",
                "}\n",
                "\n",
                "print(\"üìä Segmentation Types:\")\n",
                "for name, desc in types.items():\n",
                "    print(f\"  {name}: {desc}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. U-Net Architecture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DoubleConv(nn.Module):\n",
                "    def __init__(self, in_ch, out_ch):\n",
                "        super().__init__()\n",
                "        self.conv = nn.Sequential(\n",
                "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
                "            nn.BatchNorm2d(out_ch),\n",
                "            nn.ReLU(inplace=True),\n",
                "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
                "            nn.BatchNorm2d(out_ch),\n",
                "            nn.ReLU(inplace=True)\n",
                "        )\n",
                "    \n",
                "    def forward(self, x):\n",
                "        return self.conv(x)\n",
                "\n",
                "class UNet(nn.Module):\n",
                "    def __init__(self, n_channels=3, n_classes=1):\n",
                "        super().__init__()\n",
                "        # Encoder\n",
                "        self.enc1 = DoubleConv(n_channels, 64)\n",
                "        self.enc2 = DoubleConv(64, 128)\n",
                "        self.enc3 = DoubleConv(128, 256)\n",
                "        self.enc4 = DoubleConv(256, 512)\n",
                "        self.pool = nn.MaxPool2d(2)\n",
                "        \n",
                "        # Bottleneck\n",
                "        self.bottleneck = DoubleConv(512, 1024)\n",
                "        \n",
                "        # Decoder\n",
                "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
                "        self.dec4 = DoubleConv(1024, 512)\n",
                "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
                "        self.dec3 = DoubleConv(512, 256)\n",
                "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
                "        self.dec2 = DoubleConv(256, 128)\n",
                "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
                "        self.dec1 = DoubleConv(128, 64)\n",
                "        \n",
                "        self.out = nn.Conv2d(64, n_classes, 1)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # Encoder\n",
                "        e1 = self.enc1(x)\n",
                "        e2 = self.enc2(self.pool(e1))\n",
                "        e3 = self.enc3(self.pool(e2))\n",
                "        e4 = self.enc4(self.pool(e3))\n",
                "        \n",
                "        # Bottleneck\n",
                "        b = self.bottleneck(self.pool(e4))\n",
                "        \n",
                "        # Decoder with skip connections\n",
                "        d4 = self.dec4(torch.cat([self.up4(b), e4], dim=1))\n",
                "        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1))\n",
                "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
                "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
                "        \n",
                "        return torch.sigmoid(self.out(d1))\n",
                "\n",
                "unet = UNet().to(device)\n",
                "print(f\"U-Net parameters: {sum(p.numel() for p in unet.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Dice Loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DiceLoss(nn.Module):\n",
                "    def __init__(self, smooth=1.):\n",
                "        super().__init__()\n",
                "        self.smooth = smooth\n",
                "    \n",
                "    def forward(self, pred, target):\n",
                "        pred = pred.view(-1)\n",
                "        target = target.view(-1)\n",
                "        intersection = (pred * target).sum()\n",
                "        return 1 - (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
                "\n",
                "# Combined loss\n",
                "class CombinedLoss(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.bce = nn.BCELoss()\n",
                "        self.dice = DiceLoss()\n",
                "    \n",
                "    def forward(self, pred, target):\n",
                "        return self.bce(pred, target) + self.dice(pred, target)\n",
                "\n",
                "print(\"‚úÖ Loss functions ready\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Mask R-CNN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torchvision.models.detection import maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights\n",
                "\n",
                "weights = MaskRCNN_ResNet50_FPN_Weights.DEFAULT\n",
                "mask_rcnn = maskrcnn_resnet50_fpn(weights=weights).to(device)\n",
                "mask_rcnn.eval()\n",
                "\n",
                "print(f\"‚úÖ Mask R-CNN loaded\")\n",
                "print(f\"Output: boxes + labels + scores + masks\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "comparison = pd.DataFrame({\n",
                "    'Model': ['U-Net', 'DeepLabV3', 'Mask R-CNN', 'SAM'],\n",
                "    'Task': ['Semantic', 'Semantic', 'Instance', 'Any'],\n",
                "    'Use Case': ['Medical', 'General', 'Object masks', 'Zero-shot'],\n",
                "    'Speed': ['Fast', 'Medium', 'Slow', 'Slow']\n",
                "})\n",
                "\n",
                "display(comparison)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Key Takeaways\n",
                "1. U-Net: Best for medical/binary segmentation\n",
                "2. Mask R-CNN: Instance segmentation with detection\n",
                "3. Dice Loss: Better for class imbalance\n",
                "4. SAM: Zero-shot segmentation (state-of-art)\n",
                "\n",
                "**Next**: 14_cv_generative_models.ipynb"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}