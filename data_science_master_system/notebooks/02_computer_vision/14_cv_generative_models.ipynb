{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé® Generative Models: GANs, VAE & Diffusion\n",
                "\n",
                "**Author**: Data Science Master System  \n",
                "**Difficulty**: ‚≠ê‚≠ê‚≠ê‚≠ê Advanced  \n",
                "**Time**: 90 minutes  \n",
                "**Prerequisites**: 13_cv_image_segmentation\n",
                "\n",
                "## Learning Objectives\n",
                "- Understand generative vs discriminative models\n",
                "- Implement GAN and VAE architectures\n",
                "- Learn about Stable Diffusion\n",
                "- Image-to-image translation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. GAN: Generator & Discriminator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Generator(nn.Module):\n",
                "    def __init__(self, latent_dim=100, img_shape=(1, 28, 28)):\n",
                "        super().__init__()\n",
                "        self.img_shape = img_shape\n",
                "        self.model = nn.Sequential(\n",
                "            nn.Linear(latent_dim, 256),\n",
                "            nn.LeakyReLU(0.2),\n",
                "            nn.BatchNorm1d(256),\n",
                "            nn.Linear(256, 512),\n",
                "            nn.LeakyReLU(0.2),\n",
                "            nn.BatchNorm1d(512),\n",
                "            nn.Linear(512, 1024),\n",
                "            nn.LeakyReLU(0.2),\n",
                "            nn.BatchNorm1d(1024),\n",
                "            nn.Linear(1024, int(np.prod(img_shape))),\n",
                "            nn.Tanh()\n",
                "        )\n",
                "    \n",
                "    def forward(self, z):\n",
                "        img = self.model(z)\n",
                "        return img.view(img.size(0), *self.img_shape)\n",
                "\n",
                "class Discriminator(nn.Module):\n",
                "    def __init__(self, img_shape=(1, 28, 28)):\n",
                "        super().__init__()\n",
                "        self.model = nn.Sequential(\n",
                "            nn.Linear(int(np.prod(img_shape)), 512),\n",
                "            nn.LeakyReLU(0.2),\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(512, 256),\n",
                "            nn.LeakyReLU(0.2),\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(256, 1),\n",
                "            nn.Sigmoid()\n",
                "        )\n",
                "    \n",
                "    def forward(self, img):\n",
                "        return self.model(img.view(img.size(0), -1))\n",
                "\n",
                "G = Generator().to(device)\n",
                "D = Discriminator().to(device)\n",
                "print(f\"Generator params: {sum(p.numel() for p in G.parameters()):,}\")\n",
                "print(f\"Discriminator params: {sum(p.numel() for p in D.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. VAE: Variational Autoencoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class VAE(nn.Module):\n",
                "    def __init__(self, latent_dim=20):\n",
                "        super().__init__()\n",
                "        self.latent_dim = latent_dim\n",
                "        \n",
                "        # Encoder\n",
                "        self.encoder = nn.Sequential(\n",
                "            nn.Linear(784, 400),\n",
                "            nn.ReLU()\n",
                "        )\n",
                "        self.fc_mu = nn.Linear(400, latent_dim)\n",
                "        self.fc_var = nn.Linear(400, latent_dim)\n",
                "        \n",
                "        # Decoder\n",
                "        self.decoder = nn.Sequential(\n",
                "            nn.Linear(latent_dim, 400),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(400, 784),\n",
                "            nn.Sigmoid()\n",
                "        )\n",
                "    \n",
                "    def encode(self, x):\n",
                "        h = self.encoder(x.view(-1, 784))\n",
                "        return self.fc_mu(h), self.fc_var(h)\n",
                "    \n",
                "    def reparameterize(self, mu, logvar):\n",
                "        std = torch.exp(0.5 * logvar)\n",
                "        eps = torch.randn_like(std)\n",
                "        return mu + eps * std\n",
                "    \n",
                "    def decode(self, z):\n",
                "        return self.decoder(z)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        mu, logvar = self.encode(x)\n",
                "        z = self.reparameterize(mu, logvar)\n",
                "        return self.decode(z), mu, logvar\n",
                "\n",
                "vae = VAE().to(device)\n",
                "print(f\"VAE params: {sum(p.numel() for p in vae.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Diffusion Models Overview"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "diffusion_info = '''\n",
                "üé® Diffusion Models (Stable Diffusion, DALL-E 3):\n",
                "\n",
                "1. Forward Process: Add noise gradually\n",
                "   x_t = ‚àö(Œ±_t) * x_0 + ‚àö(1-Œ±_t) * Œµ\n",
                "\n",
                "2. Reverse Process: Learn to denoise\n",
                "   Model predicts noise Œµ at each step\n",
                "\n",
                "3. Training: \n",
                "   - Add noise to image\n",
                "   - Predict the noise\n",
                "   - MSE loss between predicted and actual noise\n",
                "\n",
                "4. Generation:\n",
                "   - Start with pure noise\n",
                "   - Iteratively denoise (50-1000 steps)\n",
                "   - Get final image\n",
                "'''\n",
                "print(diffusion_info)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using Stable Diffusion (HuggingFace)\n",
                "sd_code = '''\n",
                "from diffusers import StableDiffusionPipeline\n",
                "import torch\n",
                "\n",
                "pipe = StableDiffusionPipeline.from_pretrained(\n",
                "    \"runwayml/stable-diffusion-v1-5\",\n",
                "    torch_dtype=torch.float16\n",
                ").to(\"cuda\")\n",
                "\n",
                "image = pipe(\"A beautiful sunset over mountains\").images[0]\n",
                "image.save(\"generated.png\")\n",
                "'''\n",
                "print(\"üìã Stable Diffusion Usage:\")\n",
                "print(sd_code)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "comparison = pd.DataFrame({\n",
                "    'Model': ['GAN', 'VAE', 'Diffusion', 'Flow'],\n",
                "    'Quality': ['High', 'Medium', 'Very High', 'High'],\n",
                "    'Training': ['Unstable', 'Stable', 'Stable', 'Stable'],\n",
                "    'Speed': ['Fast', 'Fast', 'Slow', 'Medium'],\n",
                "    'Diversity': ['Mode collapse risk', 'Good', 'Excellent', 'Good']\n",
                "})\n",
                "\n",
                "display(comparison)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Applications"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "applications = [\n",
                "    ('üñºÔ∏è Image Generation', 'Art, design, content creation'),\n",
                "    ('üîÑ Style Transfer', 'Apply artistic styles to photos'),\n",
                "    ('‚¨ÜÔ∏è Super Resolution', 'Enhance image quality'),\n",
                "    ('üé≠ Face Generation', 'Synthetic faces for privacy'),\n",
                "    ('üè• Medical', 'Synthetic training data'),\n",
                "    ('üéÆ Gaming', 'Asset generation, textures'),\n",
                "]\n",
                "\n",
                "print(\"üöÄ Generative Model Applications:\")\n",
                "for name, desc in applications:\n",
                "    print(f\"  {name}: {desc}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Key Takeaways\n",
                "1. GANs: Fast but unstable training\n",
                "2. VAEs: Stable, good for compression\n",
                "3. Diffusion: Best quality, slow generation\n",
                "4. Use case determines model choice\n",
                "\n",
                "**Next**: 15_nlp_text_classification.ipynb"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}