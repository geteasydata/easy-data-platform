{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìù NLP Transformers - Exercises\n",
                "\n",
                "Practice with text classification, sentiment analysis, and transformers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 1: Fill-in-the-Blank (‚≠ê)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 1.1: Create a sentiment analysis pipeline\n",
                "from transformers import ________\n",
                "\n",
                "classifier = ________('sentiment-analysis')\n",
                "result = classifier(\"I love this product!\")\n",
                "# Should output: [{'label': 'POSITIVE', 'score': 0.99}]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 1.2: Load BERT tokenizer\n",
                "from transformers import ________\n",
                "\n",
                "tokenizer = ________.from_pretrained('________-base-uncased')\n",
                "tokens = tokenizer(\"Hello world\", return_tensors='pt')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 2: Code Completion (‚≠ê‚≠ê)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 2.1: Fine-tune BERT for sentiment\n",
                "# Complete the training loop\n",
                "\n",
                "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
                "from torch.utils.data import DataLoader\n",
                "import torch\n",
                "\n",
                "def train_step(model, batch, optimizer):\n",
                "    model.train()\n",
                "    # 1. Zero gradients\n",
                "    # YOUR CODE\n",
                "    \n",
                "    # 2. Forward pass\n",
                "    outputs = # YOUR CODE - pass input_ids and attention_mask to model\n",
                "    \n",
                "    # 3. Compute loss (outputs.loss)\n",
                "    loss = # YOUR CODE\n",
                "    \n",
                "    # 4. Backward pass\n",
                "    # YOUR CODE\n",
                "    \n",
                "    # 5. Update weights\n",
                "    # YOUR CODE\n",
                "    \n",
                "    return loss.item()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 3: Debug This Code (‚≠ê‚≠ê‚≠ê)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 3.1: Fix 3 bugs\n",
                "\n",
                "from transformers import BertForSequenceClassification, BertTokenizer\n",
                "\n",
                "# Bug 1: Wrong tokenizer for model\n",
                "tokenizer = GPT2Tokenizer.from_pretrained('bert-base-uncased')\n",
                "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
                "\n",
                "texts = [\"Great product!\", \"Terrible experience\"]\n",
                "# Bug 2: Missing padding and truncation\n",
                "inputs = tokenizer(texts, return_tensors='pt')\n",
                "\n",
                "# Bug 3: Should be model.eval() for inference\n",
                "model.train()\n",
                "with torch.no_grad():\n",
                "    outputs = model(**inputs)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Level 4: Business Challenge (‚≠ê‚≠ê‚≠ê‚≠ê)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHALLENGE: Multi-language Customer Support Classification\n",
                "#\n",
                "# Scenario: An e-commerce platform receives customer messages in 5 languages\n",
                "# (English, Spanish, French, German, Portuguese)\n",
                "#\n",
                "# Task: Build a model that:\n",
                "# 1. Classifies intent: [order_status, refund, complaint, feedback, other]\n",
                "# 2. Works across all 5 languages\n",
                "# 3. Inference time < 50ms per message\n",
                "#\n",
                "# Constraints:\n",
                "# - Limited training data (100 examples per language per class)\n",
                "# - Must handle code-switching (mixed language messages)\n",
                "#\n",
                "# Hints:\n",
                "# - Consider multilingual models (XLM-RoBERTa, mBERT)\n",
                "# - Use distillation for speed\n",
                "\n",
                "# YOUR SOLUTION"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Quiz\n",
                "\n",
                "**Q1**: What does BERT stand for?\n",
                "\n",
                "**Q2**: Why use AdamW instead of Adam for transformers?\n",
                "\n",
                "**Q3**: What learning rate is typical for fine-tuning BERT?\n",
                "- a) 0.1\n",
                "- b) 0.001\n",
                "- c) 2e-5\n",
                "- d) 1e-1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üîë Solutions\n",
                "<details>\n",
                "<summary>Click to reveal</summary>\n",
                "\n",
                "**1.1**: pipeline, pipeline  \n",
                "**1.2**: AutoTokenizer, AutoTokenizer, bert  \n",
                "**Q1**: Bidirectional Encoder Representations from Transformers  \n",
                "**Q2**: AdamW has decoupled weight decay for better regularization  \n",
                "**Q3**: c) 2e-5  \n",
                "\n",
                "</details>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}