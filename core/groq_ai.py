"""
Groq AI Integration - Llama 3.3 70B for Expert Data Analysis
Primary AI engine for fast, intelligent data insights
"""

import os
from typing import Dict, Any, Optional, List
import pandas as pd
import json
import re

# Try to import Groq
try:
    from groq import Groq
    HAS_GROQ = True
except ImportError:
    HAS_GROQ = False

# Try to import requests for DeepSeek fallback
try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    HAS_REQUESTS = False


class GroqAI:
    """
    Groq AI Engine using Llama 3.3 70B for intelligent data analysis.
    Blazingly fast with free tier support.
    """
    
    # Default API keys (user provided)
    DEFAULT_GROQ_KEY = "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"
    DEFAULT_DEEPSEEK_KEY = "sk-0d8b9806c944495387bd466460a53932"
    
    def __init__(self, api_key: Optional[str] = None, deepseek_key: Optional[str] = None):
        """
        Initialize Groq AI with optional DeepSeek fallback.
        
        Args:
            api_key: Groq API key (or uses default/env var)
            deepseek_key: Optional DeepSeek API key for fallback
        """
        self.api_key = api_key or os.getenv('GROQ_API_KEY') or self.DEFAULT_GROQ_KEY
        self.deepseek_key = deepseek_key or os.getenv('DEEPSEEK_API_KEY') or self.DEFAULT_DEEPSEEK_KEY
        self.client = None
        self.is_configured = False
        self.active_provider = None
        self.log_messages = []
        
        self._setup()
    
    def _setup(self):
        """Setup the AI client."""
        # Try Groq first
        if HAS_GROQ and self.api_key:
            try:
                self.client = Groq(api_key=self.api_key)
                # Test connection with a simple request
                self.is_configured = True
                self.active_provider = 'groq'
                self.log("âœ… Groq API Ù…ØªØµÙ„ - Llama 3.3 70B Ø¬Ø§Ù‡Ø²")
            except Exception as e:
                self.log(f"âš ï¸ ÙØ´Ù„ Ø§ØªØµØ§Ù„ Groq: {e}")
        
        # If Groq fails, try DeepSeek
        if not self.is_configured and self.deepseek_key and HAS_REQUESTS:
            self.is_configured = True
            self.active_provider = 'deepseek'
            self.log("âœ… DeepSeek API Ù…ØªØµÙ„ ÙƒØ¨Ø¯ÙŠÙ„")
    
    def log(self, message: str):
        """Add log message."""
        self.log_messages.append(message)
        print(message)
    
    def get_log(self) -> List[str]:
        """Get all log messages."""
        return self.log_messages
    
    def _call_groq(self, prompt: str, max_tokens: int = 2000) -> str:
        """Call Groq API with Llama 3.3."""
        response = self.client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {
                    "role": "system",
                    "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­ØªØ±Ù Ø¨Ø®Ø¨Ø±Ø© 30 Ø³Ù†Ø©. ØªØ¬ÙŠØ¨ Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ¥ÙŠØ¬Ø§Ø². You are a senior data scientist with 30 years of experience."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=max_tokens,
            temperature=0.7
        )
        return response.choices[0].message.content
    
    def _call_deepseek(self, prompt: str) -> str:
        """Call DeepSeek API as fallback."""
        url = "https://api.deepseek.com/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.deepseek_key}",
            "Content-Type": "application/json"
        }
        data = {
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 2000
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        return response.json()['choices'][0]['message']['content']
    
    def _call_ai(self, prompt: str) -> str:
        """Call the active AI provider."""
        if self.active_provider == 'groq':
            return self._call_groq(prompt)
        elif self.active_provider == 'deepseek':
            return self._call_deepseek(prompt)
        else:
            raise Exception("No AI provider configured")
    
    def analyze_data_quality(self, analysis: Dict[str, Any], lang: str = 'ar') -> str:
        """Generate AI insights about data quality."""
        if not self.is_configured:
            return self._fallback_data_quality(analysis, lang)
        
        prompt = f"""
        You are a senior data scientist with 30+ years of experience.
        Analyze this dataset summary and provide expert insights:
        
        - Rows: {analysis.get('rows', 0)}
        - Columns: {analysis.get('columns', 0)}
        - Numeric columns: {len(analysis.get('numeric_columns', []))}
        - Categorical columns: {len(analysis.get('categorical_columns', []))}
        - Missing values: {analysis.get('total_missing', 0)}
        - Duplicates: {analysis.get('duplicates', 0)}
        
        Provide 3-5 key observations and recommendations.
        Language: {'Arabic' if lang == 'ar' else 'English'}
        Format: Bullet points with emojis for visual appeal.
        Keep it concise and actionable.
        """
        
        try:
            return self._call_ai(prompt)
        except Exception as e:
            self.log(f"âš ï¸ AI Error: {e}")
            return self._fallback_data_quality(analysis, lang)
    
    def generate_insights(self, results: Dict[str, Any], target_col: str, lang: str = 'ar') -> str:
        """Generate strategic business insights from ML results."""
        if not self.is_configured:
            return self._fallback_insights(results, target_col, lang)
        
        # Get top features safely
        feature_importance = results.get('feature_importance')
        if isinstance(feature_importance, pd.DataFrame) and not feature_importance.empty:
            top_features = feature_importance.head(5)['Feature'].tolist()
        else:
            top_features = []
        
        prompt = f"""
        You are a senior data scientist with 30+ years of experience advising Fortune 500 companies.
        Based on the ML analysis results below, provide strategic business recommendations:
        
        Problem Type: {results.get('problem_type', 'unknown')}
        Best Model: {results.get('best_model', 'unknown')}
        Performance Metrics: {results.get('metrics', {})}
        Top 5 Important Features: {top_features}
        Target Variable: {target_col}
        
        Provide:
        1. Performance interpretation (is it good? what does it mean for business?)
        2. Top 3 strategic recommendations based on feature importance
        3. Data quality notes and improvement suggestions
        4. Next steps for production deployment
        
        Language: {'Arabic' if lang == 'ar' else 'English'}
        Format: Professional report style with emojis and clear sections.
        Be specific and actionable.
        """
        
        try:
            return self._call_ai(prompt)
        except Exception as e:
            self.log(f"âš ï¸ AI Error: {e}")
            return self._fallback_insights(results, target_col, lang)
    
    def suggest_feature_engineering(self, df: pd.DataFrame, lang: str = 'ar') -> str:
        """Suggest feature engineering ideas based on data."""
        if not self.is_configured:
            return self._fallback_feature_suggestions(df, lang)
        
        columns_info = {col: str(df[col].dtype) for col in list(df.columns)[:20]}
        
        prompt = f"""
        As an expert data scientist, suggest feature engineering ideas for this dataset:
        
        Columns and types: {columns_info}
        Number of rows: {len(df)}
        
        Suggest:
        1. Derived features that could be created
        2. Feature combinations or interactions
        3. Time-based features if applicable
        4. Encoding strategies for categorical variables
        
        Language: {'Arabic' if lang == 'ar' else 'English'}
        Be specific and practical.
        """
        
        try:
            return self._call_ai(prompt)
        except Exception as e:
            self.log(f"âš ï¸ AI Error: {e}")
            return self._fallback_feature_suggestions(df, lang)
    
    def understand_data(self, df: pd.DataFrame, target_col: Optional[str] = None) -> Dict[str, Any]:
        """
        Use AI to deeply understand the data.
        
        Returns insights about:
        - What each column represents
        - Best cleaning strategy
        - Suggested features
        - Potential issues
        - Recommended model
        """
        summary = self._create_data_summary(df, target_col)
        
        if not self.is_configured:
            return self._rule_based_understanding(df, summary)
        
        prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­ØªØ±Ù. Ø­Ù„Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ£Ø¹Ø·Ù†ÙŠ:

1. Ù…Ø§Ø°Ø§ ÙŠÙ…Ø«Ù„ ÙƒÙ„ Ø¹Ù…ÙˆØ¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¬Ø­ØŸ
2. Ù…Ø§ Ø£ÙØ¶Ù„ Ø·Ø±ÙŠÙ‚Ø© Ù„ØªÙ†Ø¸ÙŠÙ ÙƒÙ„ Ø¹Ù…ÙˆØ¯ØŸ
3. Ù…Ø§ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ØŸ
4. Ù…Ø§ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŸ
5. Ù…Ø§ Ù†ÙˆØ¹ Ù†Ù…ÙˆØ°Ø¬ ML Ø§Ù„Ø£ÙØ¶Ù„ØŸ

{summary}

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·:
{{
    "column_meanings": {{"col_name": "Ø§Ù„Ù…Ø¹Ù†Ù‰"}},
    "cleaning_strategy": {{"col_name": "Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"}},
    "suggested_features": ["Ù…ÙŠØ²Ø©1", "Ù…ÙŠØ²Ø©2"],
    "potential_issues": ["Ù…Ø´ÙƒÙ„Ø©1", "Ù…Ø´ÙƒÙ„Ø©2"],
    "recommended_model": "Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬",
    "confidence": 0.8
}}
"""
        try:
            result_text = self._call_ai(prompt)
            result = self._parse_json_response(result_text)
            result['ai_powered'] = True
            result['provider'] = self.active_provider
            self.log("ðŸ¤– ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
            return result
        except Exception as e:
            self.log(f"âš ï¸ AI Error: {e}")
            return self._rule_based_understanding(df, summary)
    
    def explain_results(self, results: Dict, target_col: str, lang: str = 'ar') -> str:
        """Use AI to explain model results in human language."""
        if not self.is_configured:
            return self._rule_based_explanation(results, target_col, lang)
        
        # Get feature importance safely
        feature_importance = results.get('feature_importance')
        if isinstance(feature_importance, pd.DataFrame):
            top_features = feature_importance.head(5).to_dict()
        else:
            top_features = {}
        
        prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª ØªØ´Ø±Ø­ Ù„Ù„Ù…Ø¯ÙŠØ± Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ.

Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:
- Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: {results.get('problem_type', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
- Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬: {results.get('best_model', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
- Ø§Ù„Ø¯Ù‚Ø©: {results.get('metrics', {})}
- Ø£Ù‡Ù… Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª: {top_features}

Ø§ÙƒØªØ¨ Ø´Ø±Ø­Ø§Ù‹ Ø¨Ø³ÙŠØ·Ø§Ù‹ (3-5 Ø¬Ù…Ù„) ÙŠÙÙ‡Ù…Ù‡ ØºÙŠØ± Ø§Ù„ØªÙ‚Ù†ÙŠ.
Ø§Ù„Ù„ØºØ©: {'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' if lang == 'ar' else 'English'}
"""
        try:
            return self._call_ai(prompt)
        except Exception as e:
            self.log(f"âš ï¸ AI Error: {e}")
            return self._rule_based_explanation(results, target_col, lang)
    
    def _create_data_summary(self, df: pd.DataFrame, target_col: Optional[str] = None) -> str:
        """Create a text summary of the data for the AI."""
        summary = f"""
Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ {len(df)} ØµÙ Ùˆ {len(df.columns)} Ø¹Ù…ÙˆØ¯.

Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:
"""
        for col in df.columns:
            dtype = df[col].dtype
            n_unique = df[col].nunique()
            n_missing = df[col].isna().sum()
            sample = df[col].dropna().head(3).tolist()
            
            summary += f"- {col}: Ù†ÙˆØ¹={dtype}, Ù‚ÙŠÙ… ÙØ±ÙŠØ¯Ø©={n_unique}, Ù…ÙÙ‚ÙˆØ¯={n_missing}, Ø¹ÙŠÙ†Ø©={sample}\n"
        
        if target_col:
            summary += f"\nØ¹Ù…ÙˆØ¯ Ø§Ù„Ù‡Ø¯Ù: {target_col}"
        
        return summary
    
    def _parse_json_response(self, text: str) -> Dict:
        """Parse AI response to extract JSON."""
        try:
            json_match = re.search(r'\{.*\}', text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except:
            pass
        
        return {"raw_response": text, "parse_error": True}
    
    def _fallback_data_quality(self, analysis: Dict[str, Any], lang: str) -> str:
        """Fallback when AI is not available."""
        if lang == 'ar':
            insights = []
            insights.append(f"ðŸ“Š **Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: {analysis.get('rows', 0)} ØµÙ Ã— {analysis.get('columns', 0)} Ø¹Ù…ÙˆØ¯")
            
            total_missing = analysis.get('total_missing', 0)
            rows = analysis.get('rows', 1)
            cols = analysis.get('columns', 1)
            
            if total_missing > 0:
                pct = (total_missing / (rows * cols)) * 100
                insights.append(f"âš ï¸ **Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©**: {total_missing} ({pct:.1f}%) - ØªÙ… Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹")
            else:
                insights.append("âœ… **Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©**")
            
            if analysis.get('duplicates', 0) > 0:
                insights.append(f"ðŸ—‘ï¸ **ØµÙÙˆÙ Ù…ÙƒØ±Ø±Ø©**: {analysis['duplicates']} - ØªÙ… Ø¥Ø²Ø§Ù„ØªÙ‡Ø§")
            
            if analysis.get('numeric_columns'):
                insights.append(f"ðŸ”¢ **Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ©**: {len(analysis['numeric_columns'])}")
            if analysis.get('categorical_columns'):
                insights.append(f"ðŸ·ï¸ **Ø£Ø¹Ù…Ø¯Ø© Ù†ØµÙŠØ©**: {len(analysis['categorical_columns'])}")
            
            return "\n".join(insights)
        else:
            insights = []
            insights.append(f"ðŸ“Š **Data Size**: {analysis.get('rows', 0)} rows Ã— {analysis.get('columns', 0)} columns")
            
            total_missing = analysis.get('total_missing', 0)
            rows = analysis.get('rows', 1)
            cols = analysis.get('columns', 1)
            
            if total_missing > 0:
                pct = (total_missing / (rows * cols)) * 100
                insights.append(f"âš ï¸ **Missing Values**: {total_missing} ({pct:.1f}%) - Auto-handled")
            else:
                insights.append("âœ… **No missing values**")
            
            if analysis.get('duplicates', 0) > 0:
                insights.append(f"ðŸ—‘ï¸ **Duplicate Rows**: {analysis['duplicates']} - Removed")
            
            if analysis.get('numeric_columns'):
                insights.append(f"ðŸ”¢ **Numeric Columns**: {len(analysis['numeric_columns'])}")
            if analysis.get('categorical_columns'):
                insights.append(f"ðŸ·ï¸ **Categorical Columns**: {len(analysis['categorical_columns'])}")
            
            return "\n".join(insights)
    
    def _fallback_insights(self, results: Dict[str, Any], target_col: str, lang: str) -> str:
        """Fallback insights when AI is not available."""
        metrics = results.get('metrics', {})
        
        feature_importance = results.get('feature_importance')
        if isinstance(feature_importance, pd.DataFrame) and not feature_importance.empty:
            top_features = feature_importance.head(3)['Feature'].tolist()
        else:
            top_features = []
        
        if lang == 'ar':
            insights = []
            
            if results.get('problem_type') == 'classification':
                acc = metrics.get('accuracy', 0)
                if acc > 0.90:
                    insights.append(f"âœ… **Ø£Ø¯Ø§Ø¡ Ù…Ù…ØªØ§Ø²** (Ø¯Ù‚Ø©: {acc:.1%}): Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¥Ù†ØªØ§Ø¬!")
                elif acc > 0.75:
                    insights.append(f"âš ï¸ **Ø£Ø¯Ø§Ø¡ Ø¬ÙŠØ¯** (Ø¯Ù‚Ø©: {acc:.1%}): ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ù‚Ø¨Ø© ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ø§Ù„Ø§Øª")
                else:
                    insights.append(f"âŒ **Ø£Ø¯Ø§Ø¡ Ø¶Ø¹ÙŠÙ** (Ø¯Ù‚Ø©: {acc:.1%}): Ù†Ø­ØªØ§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ù…ÙŠØ²Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©")
            else:
                r2 = metrics.get('r2', 0)
                if r2 > 0.80:
                    insights.append(f"âœ… **ØªÙØ³ÙŠØ± Ù‚ÙˆÙŠ** (RÂ²: {r2:.2f}): Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠÙØ³Ø± Ù…Ø¹Ø¸Ù… Ø§Ù„ØªØ¨Ø§ÙŠÙ†")
                else:
                    insights.append(f"âš ï¸ **ØªÙØ³ÙŠØ± Ù…ØªÙˆØ³Ø·** (RÂ²: {r2:.2f}): Ù‡Ù†Ø§Ùƒ Ø¹ÙˆØ§Ù…Ù„ ØºÙŠØ± Ù…Ø±ØµÙˆØ¯Ø©")
            
            insights.append("\n**ðŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©:**")
            if len(top_features) >= 1:
                insights.append(f"1. **{top_features[0]}** Ù‡Ùˆ Ø§Ù„Ù…Ø¤Ø«Ø± Ø§Ù„Ø£Ù‡Ù… - Ø±ÙƒØ² Ù…ÙˆØ§Ø±Ø¯Ùƒ Ù‡Ù†Ø§")
            if len(top_features) >= 2:
                insights.append(f"2. **{top_features[1]}** Ø¹Ø§Ù…Ù„ Ø«Ø§Ù†ÙˆÙŠ Ù…Ù‡Ù… - Ø±Ø§Ù‚Ø¨Ù‡ Ø¹Ù† ÙƒØ«Ø¨")
            if len(top_features) >= 3:
                insights.append(f"3. **{top_features[2]}** ÙŠØ³ØªØ­Ù‚ Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø£ÙŠØ¶Ø§Ù‹")
            
            return "\n".join(insights)
        else:
            insights = []
            
            if results.get('problem_type') == 'classification':
                acc = metrics.get('accuracy', 0)
                if acc > 0.90:
                    insights.append(f"âœ… **Excellent Performance** (Accuracy: {acc:.1%}): Production-ready!")
                elif acc > 0.75:
                    insights.append(f"âš ï¸ **Good Performance** (Accuracy: {acc:.1%}): Needs monitoring")
                else:
                    insights.append(f"âŒ **Weak Performance** (Accuracy: {acc:.1%}): More data needed")
            else:
                r2 = metrics.get('r2', 0)
                if r2 > 0.80:
                    insights.append(f"âœ… **Strong Fit** (RÂ²: {r2:.2f}): Model explains most variance")
                else:
                    insights.append(f"âš ï¸ **Moderate Fit** (RÂ²: {r2:.2f}): External factors present")
            
            insights.append("\n**ðŸ’¡ Strategic Recommendations:**")
            if len(top_features) >= 1:
                insights.append(f"1. **{top_features[0]}** is the key driver - Focus resources here")
            if len(top_features) >= 2:
                insights.append(f"2. **{top_features[1]}** is secondary but important")
            if len(top_features) >= 3:
                insights.append(f"3. **{top_features[2]}** also deserves attention")
            
            return "\n".join(insights)
    
    def _fallback_feature_suggestions(self, df: pd.DataFrame, lang: str) -> str:
        """Fallback feature suggestions."""
        if lang == 'ar':
            return """
**ðŸ’¡ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª:**
1. ðŸ”¢ Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙŠØ²Ø§Øª Ø±ÙŠØ§Ø¶ÙŠØ© (Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ØŒ Ø§Ù„Ù…ØªÙˆØ³Ø·ØŒ Ø§Ù„Ù†Ø³Ø¨)
2. ðŸ“… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙŠØ²Ø§Øª Ø²Ù…Ù†ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ ØªÙˆØ§Ø±ÙŠØ®
3. ðŸ·ï¸ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù†Ø§Ø¯Ø±Ø© ÙÙŠ ÙØ¦Ø© ÙˆØ§Ø­Ø¯Ø©
4. ðŸ“Š Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙŠØ²Ø§Øª ØªÙØ§Ø¹Ù„ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù‡Ù…Ø©
"""
        else:
            return """
**ðŸ’¡ Feature Engineering Suggestions:**
1. ðŸ”¢ Create mathematical features (sum, mean, ratios)
2. ðŸ“… Extract datetime features if dates exist
3. ðŸ·ï¸ Group rare categories together
4. ðŸ“Š Create interaction features between important columns
"""
    
    def _rule_based_understanding(self, df: pd.DataFrame, summary: str) -> Dict[str, Any]:
        """Rule-based data understanding (fallback)."""
        import numpy as np
        
        result = {
            'ai_powered': False,
            'provider': 'rule-based',
            'column_meanings': {},
            'cleaning_strategy': {},
            'suggested_features': [],
            'potential_issues': [],
            'recommended_model': 'Random Forest'
        }
        
        for col in df.columns:
            col_lower = col.lower()
            
            if any(x in col_lower for x in ['name', 'Ø§Ø³Ù…', 'Ø§Ù„Ø§Ø³Ù…']):
                result['column_meanings'][col] = 'Ø§Ø³Ù… Ø´Ø®Øµ Ø£Ùˆ ÙƒÙŠØ§Ù†'
                result['cleaning_strategy'][col] = 'ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ©'
            elif any(x in col_lower for x in ['age', 'Ø¹Ù…Ø±', 'Ø§Ù„Ø¹Ù…Ø±']):
                result['column_meanings'][col] = 'Ø¹Ù…Ø±'
                result['cleaning_strategy'][col] = 'Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø§Ù„ÙˆØ³ÙŠØ·'
            elif any(x in col_lower for x in ['salary', 'Ø±Ø§ØªØ¨', 'Ø§Ù„Ø±Ø§ØªØ¨', 'price', 'Ø³Ø¹Ø±']):
                result['column_meanings'][col] = 'Ù‚ÙŠÙ…Ø© Ù…Ø§Ù„ÙŠØ©'
                result['cleaning_strategy'][col] = 'Ø¥Ø²Ø§Ù„Ø© Ø±Ù…ÙˆØ² Ø§Ù„Ø¹Ù…Ù„Ø© ÙˆØªØ­ÙˆÙŠÙ„ Ù„Ø£Ø±Ù‚Ø§Ù…'
            elif any(x in col_lower for x in ['date', 'ØªØ§Ø±ÙŠØ®', 'Ø§Ù„ØªØ§Ø±ÙŠØ®', 'time']):
                result['column_meanings'][col] = 'ØªØ§Ø±ÙŠØ® Ø£Ùˆ ÙˆÙ‚Øª'
                result['cleaning_strategy'][col] = 'ØªØ­ÙˆÙŠÙ„ Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù†Ø©/Ø§Ù„Ø´Ù‡Ø±/Ø§Ù„ÙŠÙˆÙ…'
            elif any(x in col_lower for x in ['id', 'Ø±Ù‚Ù…', 'Ø§Ù„Ø±Ù‚Ù…', 'code']):
                result['column_meanings'][col] = 'Ù…Ø¹Ø±Ù‘Ù ÙØ±ÙŠØ¯'
                result['cleaning_strategy'][col] = 'Ø­Ø°Ù - Ù„Ø§ ÙØ§Ø¦Ø¯Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨'
            elif any(x in col_lower for x in ['email', 'Ø¨Ø±ÙŠØ¯', 'phone', 'Ù‡Ø§ØªÙ']):
                result['column_meanings'][col] = 'Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙˆØ§ØµÙ„'
                result['cleaning_strategy'][col] = 'Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯ÙˆÙ…ÙŠÙ† Ø£Ùˆ ÙƒÙˆØ¯ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'
            else:
                if df[col].dtype in ['int64', 'float64']:
                    result['column_meanings'][col] = 'Ù‚ÙŠÙ…Ø© Ø±Ù‚Ù…ÙŠØ©'
                    result['cleaning_strategy'][col] = 'Ù…Ù„Ø¡ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯ Ø¨Ø§Ù„ÙˆØ³ÙŠØ·'
                else:
                    result['column_meanings'][col] = 'Ù‚ÙŠÙ…Ø© Ù†ØµÙŠØ©/ÙØ¦ÙˆÙŠØ©'
                    result['cleaning_strategy'][col] = 'ØªØ±Ù…ÙŠØ² Ø§Ù„ÙØ¦Ø§Øª'
        
        # Detect issues
        if df.isna().sum().sum() > len(df) * len(df.columns) * 0.3:
            result['potential_issues'].append('Ù†Ø³Ø¨Ø© Ø¹Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©')
        
        if df.duplicated().sum() > len(df) * 0.1:
            result['potential_issues'].append('Ù†Ø³Ø¨Ø© Ø¹Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙƒØ±Ø±Ø©')
        
        # Suggest features
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) >= 2:
            result['suggested_features'].append('Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø¨ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©')
            result['suggested_features'].append('Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ ÙˆØ§Ù„Ù…ØªÙˆØ³Ø· Ù„Ù„ØµÙÙˆÙ')
        
        return result
    
    def _rule_based_explanation(self, results: Dict, target_col: str, lang: str) -> str:
        """Generate explanation without AI."""
        problem_type = results.get('problem_type', 'classification')
        best_model = results.get('best_model', 'Random Forest')
        metrics = results.get('metrics', {})
        
        if lang == 'ar':
            if problem_type == 'classification':
                accuracy = metrics.get('accuracy', 0) * 100
                return f"""
ðŸ“Š **Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„:**

ØªÙ… Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ {best_model} Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù€ {target_col}.
Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {accuracy:.1f}%

{'âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¬ÙŠØ¯ ÙˆÙŠÙ…ÙƒÙ† Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„ÙŠÙ‡.' if accuracy > 70 else 'âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† - Ø¬Ø±Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙƒØ«Ø±.'}
"""
            else:
                r2 = metrics.get('r2', 0) * 100
                return f"""
ðŸ“Š **Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„:**

ØªÙ… Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ {best_model} Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‚ÙŠÙ…Ø© {target_col}.
Ø¬ÙˆØ¯Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ (RÂ²): {r2:.1f}%

{'âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¬ÙŠØ¯ Ù„Ù„ØªÙ†Ø¨Ø¤Ø§Øª.' if r2 > 50 else 'âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†.'}
"""
        else:
            return f"Model {best_model} trained with {metrics}"


# Convenience function
def create_ai_engine(groq_key: Optional[str] = None, deepseek_key: Optional[str] = None) -> GroqAI:
    """Create an AI engine with Groq as primary and DeepSeek as fallback."""
    return GroqAI(api_key=groq_key, deepseek_key=deepseek_key)
